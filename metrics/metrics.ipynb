{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP42S/RG7G9Pcv6KdZ1RnzH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"id":"jXSheiZV2xBp","executionInfo":{"status":"ok","timestamp":1699396270899,"user_tz":-120,"elapsed":439,"user":{"displayName":"alex zisi","userId":"03399210032520885333"}}},"outputs":[],"source":["from sklearn.metrics import classification_report\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.metrics import confusion_matrix, f1_score\n","\n","def create_confusion_matrix(true_labels, predicted_labels, class_names):\n","    cm = confusion_matrix(true_labels, predicted_labels)\n","    plt.figure(figsize=(10, 8))\n","    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n","    plt.xlabel('Predicted')\n","    plt.ylabel('Actual')\n","    plt.title('Confusion Matrix')\n","    plt.show()\n","\n","def calculate_metrics(model):\n","  predictions = model.predict(test_data)\n","\n","  true_labels = test_data.map(lambda x, y: y).unbatch()\n","\n","  true_labels = list(tfds.as_numpy(true_labels))\n","\n","  class_report = classification_report(true_labels, predictions)\n","  print(class_report)\n","  return predictions, true_labels\n","\n","def find_most_wrong_predictions(true_labels, predictions):\n","  most_wrong_preds = []\n","\n","  for i in range(len(predictions)):\n","    true_label = true_labels[i]\n","    predicted_label = np.argmax(predictions[i])\n","    prediction_prob = predictions[i][predicted_label]\n","\n","    if true_label != predicted_label:\n","      most_wrong_preds.append((i, true_label, predicted_label, prediction_prob))\n","\n","  most_wrong_preds.sort(key=lambda x: x[3], reverse=True)\n","\n","  for idx, true_label, predicted_label, prediction_prob in most_wrong_preds[:10]:\n","    print(f\"Index: {idx}, True Label: {true_label}, Predicted Label: {predicted_label}, Probability: {prediction_prob}\")\n","\n","\n","def plot_f1_scores(true_labels, predicted_labels, class_names):\n","    f1_scores = f1_score(true_labels, predicted_labels, average=None)\n","    plt.figure(figsize=(10, 6))\n","    plt.bar(class_names, f1_scores)\n","    plt.xlabel('Class')\n","    plt.ylabel('F1-Score')\n","    plt.title('F1-Scores by Class')\n","    plt.xticks(rotation=90)\n","    plt.show()\n","\n","def visualize_predictions(test_images, true_labels, predicted_labels, class_names, prediction_probabilities):\n","    num_samples = len(test_images)\n","    sample_indices = np.random.choice(num_samples, size=5, replace=False)  # Choose 5 random samples\n","\n","    plt.figure(figsize=(15, 6))\n","    for i, idx in enumerate(sample_indices):\n","        plt.subplot(1, 5, i + 1)\n","        plt.imshow(test_images[idx])\n","        plt.title(f\"Prediction: {class_names[predicted_labels[idx]]}\\n\"\n","                  f\"Probability: {prediction_probabilities[idx]:.2f}\\n\"\n","                  f\"Ground Truth: {class_names[true_labels[idx]]}\")\n","    plt.show()"]},{"cell_type":"code","source":[],"metadata":{"id":"YpWobejR6Nbv"},"execution_count":null,"outputs":[]}]}